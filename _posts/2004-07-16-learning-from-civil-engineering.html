--- 
layout: post
typo_id: 10
title: Learning from civil engineering
---
<p>

Quote:

My friend Peter Levin pointed out to me that the analogy between software engineering and civil engineering (the building of bridges, dams, and sewers) should be used to help flesh out a potential structure of the ecosystem. Here are some more thoughts inspired by that:

</p>

<p>

<ul>

<li>

Architects, civil engineers, and contractors as part of their training learn a set curriculum, pass tests, and are often licensed. They are supposed to share a body of knowledge and experience and demonstrate competence. What thrust should be part of the training of software engineers? For years we emphasized execution speed, memory constraints, data organization, flashy graphics, and algorithms for accomplishing this all. Curricula needs to also emphasize robustness, testing, maintainability, ease of replacement, security, and verifiability.

</li>

<li>

Standards bodies publish best practices (how high should a railing be above the stair tread, how thick should a concrete footing be under a supporting pillar, etc.). Even though a project might be novel (such as a new bridge or Boston's Big Dig), there are many standards that can (and must) be applied. By standards here we mean a conservative approach that is intended to minimize error, increase security, and lower maintenance costs, not just facilitate data interchange. Like all engineering, new software, as we know, commits old errors. We need to teach the right "war stories". ??Æ???¬©

</li>

<li>

Physical projects are subject to inspection by standards bodies. When you have electrical or plumbing work done, the town inspector comes to check the work before the job can be considered finished. Transparent societal infrastructural software needs inspection. This will raise the role of independent testing entities. There is much talk about such roles in the discussion about electronic voting and gambling machines, but it is also important for the software we are covering here. These jobs -- part QA, part auditor, part private investigator -- can be very high status because of the range and depth of knowledge and experience needed. For public projects, the transparency of open source is needed to allow multiple, independent inspections. There are also different inspection specialties, including standards compliance, security and other stressing, maintainability, and functionality.

</li>

<li>

When physical projects fail (a suspension bridge twists in heavy winds, an elevated freeway falls down in an earthquake, an airplane crashes) public inquiries are performed, reports are published, and fixes are designed and retrofitted to existing projects. What we learn from failures enter the standards lexicon and is used for training and new design. We don't do this yet in the world of software. Access to the source code, the right to discuss it in detail, and the ability to search for similar code elsewhere is crucial to many such studies.

</li>

</ul>

End quote.

</p>

<p>

The original article for this can be found at <a href="http://www.bricklin.com/200yearsoftware.htm">this link</a>. Anyway, the main reason I included this was because it had never occurred to me that many software developed today will not be able to run in the next few years! More interesting is the fact that the data that were created in those formats may not even be accessible anymore! These data are not limited to the more ubiquitous format of .txt or .jpeg; they include all the more esoteric file extensions which apply to closed software architecture. We are not referring to those incremental backups you make once a day; those are ephemeral in a sense. Instead, we are referring to those data which we intend to preserve for more than a decade. A decade is not to be taken lightly in terms of the computer ages and because of this we need to find a new way to archive those information. One, as suggested by the author is to rely more on open source file formats so that in the event that the software company has gone to the drains, there exist the way to extract those information from the file. I think that is where the concept of XML comes  in.

</p>

<p>

For those worried that open source file formats are easily compromised by prowling eyes, then think of what would happen if you yourself were unable to get to the data? Moreover, that is where open-source encryption methods come into play.

</p>

<p>

This is not an issue to be taken lightly. In my future endeavors in writing software, I will definitely take this into consideration. OS X has done a pretty good job for the time being by storing the files in a somewhat XML format in its Application framework in cocoa.

</p>
